{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a tf.keras model for MNIST without clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 38s 20ms/step - loss: 0.2997 - accuracy: 0.9154 - val_loss: 0.1287 - val_accuracy: 0.9648\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 24s 14ms/step - loss: 0.1313 - accuracy: 0.9616 - val_loss: 0.0939 - val_accuracy: 0.9750\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 14s 9ms/step - loss: 0.0971 - accuracy: 0.9718 - val_loss: 0.0789 - val_accuracy: 0.9807\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0795 - accuracy: 0.9763 - val_loss: 0.0728 - val_accuracy: 0.9805\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0689 - accuracy: 0.9797 - val_loss: 0.0667 - val_accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0607 - accuracy: 0.9817 - val_loss: 0.0644 - val_accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0634 - val_accuracy: 0.9827\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0491 - accuracy: 0.9852 - val_loss: 0.0672 - val_accuracy: 0.9807\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0450 - accuracy: 0.9864 - val_loss: 0.0598 - val_accuracy: 0.9832\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 14s 8ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.0629 - val_accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f842f020a00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images  = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the baseline model and save it for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9821000099182129\n",
      "Saving model to:  /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmpulfvyker.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model and apply the clustering API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_reshape (ClusterWei  (None, 28, 28, 1)        0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_conv2d (ClusterWeig  (None, 26, 26, 12)       244       \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_max_pooling2d (Clus  (None, 13, 13, 12)       0         \n",
      " terWeights)                                                     \n",
      "                                                                 \n",
      " cluster_flatten (ClusterWei  (None, 2028)             0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_dense (ClusterWeigh  (None, 10)               40586     \n",
      " ts)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,830\n",
      "Trainable params: 20,442\n",
      "Non-trainable params: 20,388\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 13s 113ms/step - loss: 0.0535 - accuracy: 0.9833 - val_loss: 0.0788 - val_accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f840fc304f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "clustered_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=500,\n",
    "  epochs=1,\n",
    "  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9821000099182129\n",
      "Clustered test accuracy: 0.9779000282287598\n"
     ]
    }
   ],
   "source": [
    "# Minimal Test Accuracy\n",
    "_, clustered_model_accuracy = clustered_model.evaluate(\n",
    "  test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create 6x smaller models from clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving clustered model to:  /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmppqptn2gf.h5\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Create a compressible model for TensorFlow\n",
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
    "                           include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmp840768to/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered TFLite model to: /tmp/clustered_mnist.tflite\n"
     ]
    }
   ],
   "source": [
    "# compressable models for TFLite\n",
    "clustered_tflite_file = '/tmp/clustered_mnist.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "tflite_clustered_model = converter.convert()\n",
    "with open(clustered_tflite_file, 'wb') as f:\n",
    "    f.write(tflite_clustered_model)\n",
    "print('Saved clustered TFLite model to:', clustered_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to actually compress the models via gzip and measure the zipped size\n",
    "def get_gzipped_model_size(file):\n",
    "    # It returns the size of the gzipped model in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78206.00 bytes\n",
      "Size of gzipped clustered Keras model: 12911.00 bytes\n",
      "Size of gzipped clustered TFlite model: 12488.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))\n",
    "print(\"Size of gzipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model_size(clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an 8x smaller TFLite model from combining weight clustering and post-training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmpcq604uh5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmpcq604uh5/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and clustered TFLite model to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmp3tu_8482.tflite\n",
      "Size of gzipped baseline Keras model: 78206.00 bytes\n",
      "Size of gzipped clustered and quantized TFlite model: 9655.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the persistence of accuracy from TF to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to evaluate the TFLite model on the test dataset\n",
    "def eval_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
