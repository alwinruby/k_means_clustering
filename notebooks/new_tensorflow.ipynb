{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a tf.keras model for MNIST without clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 20s 11ms/step - loss: 0.3039 - accuracy: 0.9151 - val_loss: 0.1323 - val_accuracy: 0.9648\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.1320 - accuracy: 0.9621 - val_loss: 0.0933 - val_accuracy: 0.9742\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 20s 12ms/step - loss: 0.0919 - accuracy: 0.9733 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 20s 12ms/step - loss: 0.0735 - accuracy: 0.9793 - val_loss: 0.0701 - val_accuracy: 0.9817\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0650 - val_accuracy: 0.9817\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 22s 13ms/step - loss: 0.0537 - accuracy: 0.9841 - val_loss: 0.0609 - val_accuracy: 0.9833\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0481 - accuracy: 0.9857 - val_loss: 0.0597 - val_accuracy: 0.9847\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 18s 11ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 0.0580 - val_accuracy: 0.9855\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 20s 12ms/step - loss: 0.0388 - accuracy: 0.9887 - val_loss: 0.0569 - val_accuracy: 0.9847\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 22s 13ms/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 0.0577 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1fa020a00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images  = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the baseline model and save it for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9815000295639038\n",
      "Saving model to:  /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmp4ek92y82.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model and apply the clustering API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_reshape (ClusterWei  (None, 28, 28, 1)        0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_conv2d (ClusterWeig  (None, 26, 26, 12)       244       \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_max_pooling2d (Clus  (None, 13, 13, 12)       0         \n",
      " terWeights)                                                     \n",
      "                                                                 \n",
      " cluster_flatten (ClusterWei  (None, 2028)             0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_dense (ClusterWeigh  (None, 10)               40586     \n",
      " ts)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,830\n",
      "Trainable params: 20,442\n",
      "Non-trainable params: 20,388\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 12s 102ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0628 - val_accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1da8b1190>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "clustered_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=500,\n",
    "  epochs=1,\n",
    "  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9815000295639038\n",
      "Clustered test accuracy: 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "# Minimal Test Accuracy\n",
    "_, clustered_model_accuracy = clustered_model.evaluate(\n",
    "  test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create 6x smaller models from clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving clustered model to:  /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmp_bqqmnrt.h5\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Create a compressible model for TensorFlow\n",
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
    "                           include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmpyvhwpvwz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered TFLite model to: /tmp/clustered_mnist.tflite\n"
     ]
    }
   ],
   "source": [
    "# compressable models for TFLite\n",
    "clustered_tflite_file = '/tmp/clustered_mnist.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "tflite_clustered_model = converter.convert()\n",
    "with open(clustered_tflite_file, 'wb') as f:\n",
    "    f.write(tflite_clustered_model)\n",
    "print('Saved clustered TFLite model to:', clustered_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to actually compress the models via gzip and measure the zipped size\n",
    "def get_gzipped_model_size(file):\n",
    "    # It returns the size of the gzipped model in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78213.00 bytes\n",
      "Size of gzipped clustered Keras model: 12765.00 bytes\n",
      "Size of gzipped clustered TFlite model: 12347.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))\n",
    "print(\"Size of gzipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model_size(clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an 8x smaller TFLite model from combining weight clustering and post-training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmpl9pzm_8y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmpl9pzm_8y/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and clustered TFLite model to: /var/folders/gb/4t3qb3rn74q3j_03hdn28vwr0000gn/T/tmpq5ucop6t.tflite\n",
      "Size of gzipped baseline Keras model: 78213.00 bytes\n",
      "Size of gzipped clustered and quantized TFlite model: 9466.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
